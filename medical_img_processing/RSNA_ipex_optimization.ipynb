{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61b72307-8ed9-41ad-ac6b-9909bdf027f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5725afc3-439b-47e5-8746-d642aa201125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): _IPEXConv2d()\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "      (downsample): Module(\n",
       "        (0): _IPEXConv2d()\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "      (downsample): Module(\n",
       "        (0): _IPEXConv2d()\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "      (downsample): Module(\n",
       "        (0): _IPEXConv2d()\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): _IPEXConv2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): _IPEXConv2d()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): _IPEXLinear()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cpu')  # Use CPU for loading the model\n",
    "model = torch.load('pneumonia11.pth', map_location=device)\n",
    "model = ipex.optimize(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb566a49-abb1-4f1d-b223-dc9e293a712f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "import torchvision.transforms as transforms\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52467ef6-d978-40c7-a571-279fdcca9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "658a4337-aea5-4ab3-9ea7-9aae5b3cfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"pneumonia11.pth\", map_location=device)\n",
    "model = ipex.optimize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00aeda71-9155-417a-9f24-5b29513e4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"ipex_pneumonia.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d432c36-fdc6-4f9a-a88b-ef09420d38cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 175 ms, sys: 0 ns, total: 175 ms\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_image_path = 'test_dicom.dcm'\n",
    "test_image = Image.fromarray((dcmread(test_image_path).pixel_array / 255.0 * 255).clip(0, 255).astype(np.uint8)).convert('RGB')\n",
    "test_image = transform(test_image).unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea41a797-893d-4cb1-bfdd-fd1b057c7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 900 ms, sys: 76 ms, total: 976 ms\n",
      "Wall time: 90.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = torch.load(\"ipex_pneumonia.pth\")\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1259a4d2-3990-4721-9106-4e14350ff025",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  original_name=GraphModule\n",
      "  (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "  (relu): ReLU(original_name=ReLU)\n",
      "  (maxpool): MaxPool2d(original_name=MaxPool2d)\n",
      "  (layer1): Module(\n",
      "    original_name=Module\n",
      "    (0): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "    )\n",
      "    (1): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Module(\n",
      "    original_name=Module\n",
      "    (0): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (downsample): Module(\n",
      "        original_name=Module\n",
      "        (0): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Module(\n",
      "    original_name=Module\n",
      "    (0): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (downsample): Module(\n",
      "        original_name=Module\n",
      "        (0): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Module(\n",
      "    original_name=Module\n",
      "    (0): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (downsample): Module(\n",
      "        original_name=Module\n",
      "        (0): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      )\n",
      "    )\n",
      "    (1): Module(\n",
      "      original_name=Module\n",
      "      (conv1): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "      (relu): ReLU(original_name=ReLU)\n",
      "      (conv2): _IPEXConv2d(original_name=_IPEXConv2d)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(original_name=AdaptiveAvgPool2d)\n",
      "  (fc): _IPEXLinear(original_name=_IPEXLinear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trace_model = torch.jit.trace(model, test_image)\n",
    "script_model = torch.jit.script(trace_model)\n",
    "print(script_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "536d45e5-c0ac-4d19-838e-4de2d69e897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 222 ms, sys: 0 ns, total: 222 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = trace_model(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8966692-2072-49aa-87d2-776d3561b696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freeze_model = torch.jit.freeze(script_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a42118c7-89c4-49b2-8885-9a810ea00e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 281 ms, sys: 4.94 ms, total: 286 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = freeze_model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385f652-af2e-498a-b6a8-b352b7baf4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03aca920-480c-4340-a628-5e35b9146859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.67 s, sys: 2.49 ms, total: 5.68 s\n",
      "Wall time: 488 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range( 0 , 15 ) :\n",
    "    with torch.no_grad():\n",
    "        model_pred = model(test_image)\n",
    "        script_pred = script_model(test_image)\n",
    "        trace_pred = trace_model(test_image)\n",
    "        freeze_pred = freeze_model(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39832173-a6ca-4e68-ae80-de7fce3593b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98.7 ms, sys: 209 µs, total: 98.9 ms\n",
      "Wall time: 9.71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "901ccfcc-72c8-41ab-98a4-3f8e91de4cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.1 ms, sys: 3.69 ms, total: 94.8 ms\n",
      "Wall time: 8.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = script_model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfb4adb8-c968-4b8e-bbe1-9bf74827e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.2 ms, sys: 90 µs, total: 97.3 ms\n",
      "Wall time: 7.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = trace_model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa1a856c-1973-4a57-ab3f-cdebc1dff9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 0 ns, total: 176 ms\n",
      "Wall time: 17.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    prediction = freeze_model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cdc13d3-1a53-4929-8ab9-7f3796a4ed49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.jit.save(script_model, \"script_model.pth\")\n",
    "torch.jit.save(trace_model, \"trace_model.pth\")\n",
    "torch.jit.save(freeze_model, \"freeze_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ed2f4-d71d-4a47-a6ea-b4794d10d0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d05b8fa-bab6-4259-8517-925851a87e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from intel_extension_for_pytorch.quantization import prepare, convert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04b04097-f443-48c7-93de-c101ec1e9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicQuantize(model_fp32, data):\n",
    "    # Acquire inference times for dynamic quantization INT8 model\n",
    "    qconfig_dynamic = ipex.quantization.default_dynamic_qconfig\n",
    "    print(\"Quantize Model with Dynamic Quantization ...\")\n",
    "\n",
    "    prepared_model_dynamic = prepare(model_fp32, qconfig_dynamic, example_inputs=data, inplace=False)\n",
    "\n",
    "    converted_model_dynamic = convert(prepared_model_dynamic)\n",
    "    with torch.no_grad():\n",
    "        traced_model_dynamic = torch.jit.trace(converted_model_dynamic, data)\n",
    "        traced_model_dynamic = torch.jit.freeze(traced_model_dynamic)\n",
    "\n",
    "    # save the quantized dynamic model \n",
    "    traced_model_dynamic.save(\"dynamic_quantized_trace_model.pth\")\n",
    "    return traced_model_dynamic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6af8f71-fbf7-482c-8d4f-a9cc0cc3e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantize Model with Dynamic Quantization ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=GraphModule)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = test_image\n",
    "\n",
    "model = torch.load(\"trace_model.pth\") \n",
    "dynamicQuantize( model , data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b659e43f-d41e-46f6-8caa-f2ad8b692b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( 0 , 50 ) :\n",
    "    with torch.no_grad():\n",
    "        quant_trace = model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e483ba8-f913-4ae0-bee3-149ce3a69cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94 ms, sys: 4.18 ms, total: 98.2 ms\n",
      "Wall time: 8.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import time \n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time() \n",
    "    quant_trace = model(data)\n",
    "    end_time = time.time() \n",
    "    total += end_time - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3c1ec-9a19-4986-b26b-2899c1461363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab5842-ef36-4cc5-95f2-244561af4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to perform inference on Resnet50 and BERT\n",
    "\"\"\"\n",
    "def runInference(model, data, modelName=\"resnet50\", dataType=\"FP32\", amx=True):\n",
    "    \"\"\"\n",
    "    Input parameters\n",
    "        model: the PyTorch model object used for inference\n",
    "        data: a sample input into the model\n",
    "        modelName: str representing the name of the model, supported values - resnet50, bert\n",
    "        dataType: str representing the data type for model parameters, supported values - FP32, BF16, INT8\n",
    "        amx: set to False to disable AMX on BF16, Default: True\n",
    "    Return value\n",
    "        inference_time: the time in seconds it takes to perform inference with the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Display run case\n",
    "    if amx:\n",
    "        isa_text = \"AVX512_CORE_AMX\"\n",
    "    else:\n",
    "        isa_text = \"AVX512_CORE_VNNI\"\n",
    "    print(\"%s %s inference with %s\" %(modelName, dataType, isa_text))\n",
    "\n",
    "    # Configure environment variable\n",
    "    if not amx:\n",
    "        os.environ[\"ONEDNN_MAX_CPU_ISA\"] = \"AVX512_CORE_VNNI\"\n",
    "    else:\n",
    "        os.environ[\"ONEDNN_MAX_CPU_ISA\"] = \"DEFAULT\"\n",
    "\n",
    "    # Special variables for specific models\n",
    "    if \"bert\" == modelName:\n",
    "        d = torch.randint(model.config.vocab_size, size=[BERT_BATCH_SIZE, BERT_SEQ_LENGTH]) # sample data input for torchscript and inference\n",
    "\n",
    "    # Prepare model for inference based on precision (FP32, BF16, INT8)\n",
    "    if \"INT8\" == dataType:\n",
    "        # Quantize model to INT8 if needed (one time)\n",
    "        model_filename = \"quantized_model_%s.pt\" %modelName\n",
    "        if not os.path.exists(model_filename):\n",
    "            qconfig = ipex.quantization.default_static_qconfig\n",
    "            prepared_model = prepare(model, qconfig, example_inputs=data, inplace=False)\n",
    "            converted_model = convert(prepared_model)\n",
    "            with torch.no_grad():\n",
    "                if \"resnet50\" == modelName:\n",
    "                    traced_model = torch.jit.trace(converted_model, data)\n",
    "                elif \"bert\" == modelName:\n",
    "                    traced_model = torch.jit.trace(converted_model, (d,), check_trace=False, strict=False)\n",
    "                else:\n",
    "                    raise Exception(\"ERROR: modelName %s is not supported. Choose from %s\" %(modelName, SUPPORTED_MODELS))\n",
    "                traced_model = torch.jit.freeze(traced_model)\n",
    "            traced_model.save(model_filename)\n",
    "\n",
    "        # Load INT8 model for inference\n",
    "        model = torch.jit.load(model_filename)\n",
    "        model.eval()\n",
    "        model = torch.jit.freeze(model)\n",
    "    elif \"BF16\" == dataType:\n",
    "        model = ipex.optimize(model, dtype=torch.bfloat16)\n",
    "        with torch.no_grad():\n",
    "            with torch.cpu.amp.autocast():\n",
    "                if \"resnet50\" == modelName:\n",
    "                    model = torch.jit.trace(model, data)\n",
    "                elif \"bert\" == modelName:\n",
    "                    model = torch.jit.trace(model, (d,), check_trace=False, strict=False)\n",
    "                else:\n",
    "                    raise Exception(\"ERROR: modelName %s is not supported. Choose from %s\" %(modelName, SUPPORTED_MODELS))\n",
    "                model = torch.jit.freeze(model)\n",
    "    else: # FP32\n",
    "        with torch.no_grad():\n",
    "            if \"resnet50\" == modelName:\n",
    "                model = torch.jit.trace(model, data)\n",
    "            elif \"bert\" == modelName:\n",
    "                model = torch.jit.trace(model, (d,), check_trace=False, strict=False)\n",
    "            else:\n",
    "                raise Exception(\"ERROR: modelName %s is not supported. Choose from %s\" %(modelName, SUPPORTED_MODELS))\n",
    "            model = torch.jit.freeze(model)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        if \"BF16\" == dataType:\n",
    "            with torch.cpu.amp.autocast():\n",
    "                # Warm up\n",
    "                for i in range(20):\n",
    "                    model(data)\n",
    "                \n",
    "                # Measure latency\n",
    "                start_time = time()\n",
    "                for i in range(NUM_SAMPLES):\n",
    "                    model(data)\n",
    "                end_time = time()\n",
    "        else:\n",
    "            # Warm up\n",
    "            for i in range(20):\n",
    "                model(data)\n",
    "            \n",
    "            # Measure latency\n",
    "            start_time = time()\n",
    "            for i in range(NUM_SAMPLES):\n",
    "                model(data)\n",
    "            end_time = time()\n",
    "    inference_time = end_time - start_time\n",
    "    print(\"Inference on %d samples took %.3f seconds\" %(NUM_SAMPLES, inference_time))\n",
    "\n",
    "    return inference_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
